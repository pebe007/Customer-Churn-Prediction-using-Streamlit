{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phoebe\\AppData\\Local\\Temp\\ipykernel_56252\\638990552.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.input_df[col].fillna(value, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hyperparameters: {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 200}\n",
      "Accuracy: 0.8621201445568752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      6486\n",
      "           1       0.76      0.52      0.62      1766\n",
      "\n",
      "    accuracy                           0.86      8252\n",
      "   macro avg       0.82      0.74      0.77      8252\n",
      "weighted avg       0.86      0.86      0.85      8252\n",
      "\n",
      "Tuned Hyperparameters: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}\n",
      "Accuracy: 0.8649680143108498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      6486\n",
      "           1       0.75      0.57      0.65      1766\n",
      "\n",
      "    accuracy                           0.87      8252\n",
      "   macro avg       0.82      0.76      0.78      8252\n",
      "weighted avg       0.86      0.87      0.86      8252\n",
      "\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, recall_score\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "import xgboost as xgb\n",
    "\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "class DataHandler:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.data = None\n",
    "        self.input_df = None\n",
    "        self.output_df = None\n",
    "        self.column_medians = {}\n",
    "        self.column_modes = {}\n",
    "\n",
    "    def load_data(self):\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "        self.data = self.data.drop_duplicates()\n",
    "        self.data = self.data.drop(['Unnamed: 0', 'id', 'CustomerId', 'Surname'], axis=1)\n",
    "        \n",
    "    def create_input_output(self, target_column):\n",
    "        self.output_df = self.data[target_column]\n",
    "        self.input_df = self.data.drop(target_column, axis=1)\n",
    "\n",
    "        for col in self.input_df.columns:\n",
    "            if self.input_df[col].dtype == 'float64' or self.input_df[col].dtype == 'int64':\n",
    "                self.column_medians[col] = self.input_df[col].median()\n",
    "            else:\n",
    "                self.column_modes[col] = self.input_df[col].mode()[0]\n",
    "    \n",
    "    def fill_na_with_dict(self, fill_dict):\n",
    "        for col, value in fill_dict.items():\n",
    "            if col in self.input_df.columns:\n",
    "                self.input_df[col].fillna(value, inplace=True)\n",
    "            else:\n",
    "                print(f\"Column '{col}' not found in dataframe.\")\n",
    "    \n",
    "    def encode_categorical(self):\n",
    "        categorical_cols = self.input_df.select_dtypes(include=['object']).columns\n",
    "        for col in categorical_cols:\n",
    "            self.input_df[col] = pd.factorize(self.input_df[col])[0]\n",
    "    \n",
    "\n",
    "\n",
    "class ModelHandler:\n",
    "    def __init__(self, input_data, output_data):\n",
    "        self.input_data = input_data\n",
    "        self.output_data = output_data\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = [None] * 4\n",
    "        self.robust = None\n",
    "        self.recall_score = None\n",
    "    \n",
    "    def RobustScaling(self):\n",
    "        self.robust = RobustScaler()\n",
    "        self.robust.fit_transform(self.x_train)  \n",
    "        self.robust.transform(self.x_test)\n",
    "    \n",
    "    def split_data(self, test_size=0.2, random_state=42): #split test data dengan test size 20% dari original data and original state = 42\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.input_data, self.output_data, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    def ClassificationReport(self,y_pred):\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "    \n",
    "\n",
    "def Recall_score(self,y_pred):\n",
    "        self.recall_score = recall_score(self.y_test, y_pred)\n",
    "    \n",
    "def prediction(model,x_test):\n",
    "        return model.predict(x_test)\n",
    "  \n",
    "class RandomForest:\n",
    "    def __init__(self):\n",
    "        self.y_pred = None\n",
    "        self.criterion = None\n",
    "        self.max_depth = None\n",
    "        self.n_estimators = None\n",
    "        self.model = RandomForestClassifier()\n",
    "        \n",
    "    #melakukan secara automatis tidak seperti modelling file \n",
    "    def tuningParameter(self,input_data,output_data,x_test):\n",
    "        parameters = {\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'max_depth': [2, 4, 6, 8, 10],\n",
    "            'n_estimators': [10, 50, 100, 150, 200]\n",
    "        }\n",
    "        RFClass = GridSearchCV(RandomForestClassifier(), param_grid=parameters, scoring='accuracy', cv=5)\n",
    "        RFClass.fit(input_data, output_data)\n",
    "        print(\"Tuned Hyperparameters:\", RFClass.best_params_)\n",
    "        print(\"Accuracy:\", RFClass.best_score_)\n",
    "        self.model = RandomForestClassifier(**RFClass.best_params_)  # Set the best parameters for the model\n",
    "        self.model.fit(input_data,output_data)\n",
    "        self.y_pred = self.model.predict(x_test)\n",
    "    \n",
    "        \n",
    "class MyXGBoostClassifier:\n",
    "    def __init__(self):\n",
    "        self.y_pred = None\n",
    "        self.max_depth = None\n",
    "        self.learning_rate = None\n",
    "        self.n_estimators = None\n",
    "        self.model = xgb.XGBClassifier()\n",
    "\n",
    "    def tuningParameter(self,input_data,output_data,x_test):\n",
    "        parameters = {\n",
    "            'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "            'n_estimators': [50, 100, 150, 200, 250]\n",
    "        }\n",
    "        xgb_model = GridSearchCV(xgb.XGBClassifier(), param_grid=parameters, scoring='accuracy', cv=5)\n",
    "        xgb_model.fit(input_data, output_data)\n",
    "        print(\"Tuned Hyperparameters:\", xgb_model.best_params_)\n",
    "        print(\"Accuracy:\", xgb_model.best_score_)\n",
    "        self.model = xgb.XGBClassifier(**xgb_model.best_params_)\n",
    "        self.model.fit(input_data, output_data)\n",
    "        self.y_pred = self.model.predict(x_test)\n",
    "\n",
    "# Update the instantiation\n",
    "\n",
    "  \n",
    "file_path = 'data_B.csv'  \n",
    "data_handler = DataHandler(file_path)\n",
    "data_handler.load_data()\n",
    "data_handler.create_input_output('churn')\n",
    "data_handler.fill_na_with_dict(data_handler.column_medians)\n",
    "data_handler.fill_na_with_dict(data_handler.column_modes)\n",
    "data_handler.encode_categorical()  # Encode categorical variables\n",
    "\n",
    "model_handler = ModelHandler(data_handler.input_df, data_handler.output_df)  # Initialize ModelHandler\n",
    "model_handler.split_data()\n",
    "model_handler.RobustScaling()\n",
    "\n",
    "random_forest = RandomForest()\n",
    "random_forest.tuningParameter(model_handler.x_train, model_handler.y_train, model_handler.x_test)\n",
    "random_forest_model = model_handler.ClassificationReport(random_forest.y_pred)\n",
    "random_forest_recall = recall_score(model_handler.y_test, random_forest.y_pred)  # Call recall_score directly\n",
    "\n",
    "xgboost = MyXGBoostClassifier()\n",
    "xgboost.tuningParameter(model_handler.x_train, model_handler.y_train, model_handler.x_test)\n",
    "xg_boost_model = model_handler.ClassificationReport(xgboost.y_pred)\n",
    "xg_boost_recall = recall_score(model_handler.y_test, xgboost.y_pred)\n",
    "\n",
    "if xg_boost_recall >= random_forest_recall:\n",
    "    model_used = xgboost\n",
    "else:\n",
    "    model_used = random_forest\n",
    "\n",
    "model_used.model.fit(model_handler.x_test, model_handler.y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# with open('model.pkl', 'wb') as dump_var:\n",
    "#     pickle.dump(model_used, dump_var)\n",
    "    \n",
    "# pickle_in = open('model.pkl', 'rb')\n",
    "# pickle_model = pickle.load(pickle_in)\n",
    "\n",
    "!streamlit run pickle_app.py "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
